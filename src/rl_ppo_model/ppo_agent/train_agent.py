import os
import json
import numpy as np
from stable_baselines3 import PPO
from rl_ppo_model.env.custom_env import CustomEnv

def make_json_safe(obj):
    if isinstance(obj, dict):
        return {k: make_json_safe(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [make_json_safe(v) for v in obj]
    elif isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    else:
        return obj

def train_model(env, total_steps=100_000, save_path="ppo_model.zip"):
    """è¨“ç·´ PPO æ¨¡å‹ä¸¦å„²å­˜"""
    model = PPO("MlpPolicy", env, verbose=1)
    model.learn(total_timesteps=total_steps)
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    model.save(save_path)
    print(f"âœ… æ¨¡å‹å„²å­˜è‡³ {save_path}")

def run_training_step(env, model_path=None, auto_train_if_missing=True):
    """
    å–®æ­¥æ¨è«–ï¼šè‡ªå‹•ä½¿ç”¨é è¨­æ¨¡å‹ï¼Œä¸¦åœ¨ç¼ºå¤±æ™‚è‡ªå‹•è¨“ç·´
    - envï¼šå·²åˆå§‹åŒ–çš„ CustomEnv
    - model_pathï¼šå¯é¸ï¼Œè‹¥æœªæä¾›å‰‡ä½¿ç”¨é è¨­æ¨¡å‹
    - auto_train_if_missingï¼šè‹¥æ¨¡å‹ä¸å­˜åœ¨ï¼Œæ˜¯å¦è‡ªå‹•è¨“ç·´
    - å›å‚³ dictï¼ŒåŒ…å«å‰ç«¯è¦çš„ action ç‰©ä»¶ã€rewardã€doneã€info
    """
    # 1. æº–å‚™é è¨­æ¨¡å‹è·¯å¾‘
    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    default_model_path = os.path.join(base_dir, 'models', 'default', 'default_model.zip')
    if model_path is None:
        print("ğŸ“¢ æœªæŒ‡å®šæ¨¡å‹è·¯å¾‘ï¼Œä½¿ç”¨é è¨­æ¨¡å‹")
        model_path = default_model_path

    # 2. å¦‚æœæ¨¡å‹ä¸å­˜åœ¨ï¼Œè‡ªå‹•è¨“ç·´
    if not os.path.exists(model_path):
        if auto_train_if_missing:
            print(f"âš ï¸ æ¨¡å‹ä¸å­˜åœ¨ï¼š{model_path}\nğŸš€ é–‹å§‹è‡ªå‹•è¨“ç·´é è¨­æ¨¡å‹...")
            train_model(env, total_steps=100_000, save_path=model_path)
        else:
            raise FileNotFoundError(f"âŒ æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨ï¼š{model_path}")

    # 3. è¼‰å…¥æ¨¡å‹ä¸¦æ¨è«–
    model = PPO.load(model_path, env=env)
    obs, _ = env.reset()
    action_idx, _ = model.predict(obs, deterministic=True)
    obs, reward, terminated, truncated, info = env.step(action_idx)

    # 4. æŠŠ action_idx è½‰æˆå‰ç«¯è¦çš„å®Œæ•´ç‰©ä»¶
    item = env._action_to_item(action_idx)
    action_obj = env._normalize_item(item)

    # 5. å›å‚³ dictï¼Œç›´æ¥çµ¦ jsonify
    return make_json_safe({
        "action": action_obj,
        "reward": reward,
        "done": bool(terminated or truncated),
        "info": info
    })

if __name__ == "__main__":
    # ç¯„ä¾‹å ´æ™¯è³‡æ–™ï¼Œè«‹æ›¿æ›æˆä½ çš„çœŸå¯¦ state
    scene_data = {
        "objects": [
            # {"uuid": "...", "position": {...}, ...}
        ]
    }
    env = CustomEnv(scene_data)

    # åŸ·è¡Œå–®æ­¥æ¨è«–ï¼ˆè‹¥ç„¡æ¨¡å‹æœƒè‡ªå‹•è¨“ç·´ï¼‰
    result = run_training_step(env)
    # ç›´æ¥å°å‡º JSON çµæ§‹
    print("ğŸ¯ æ¨è«–çµæœï¼š")
    print(json.dumps(result, ensure_ascii=False, indent=2))

    
